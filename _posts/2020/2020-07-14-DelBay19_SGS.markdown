---
comments: true
title: DelBay19 single generation selection (SGS) test
date: '2020-07-14 12:00'
tags:
  - DelBay19
  - deltap
  - ouliter
  - null model
  - theta
  - drift
  - WGS
categories:
  - WGS data analysis
---

### Test for single-generation selection

In [Within-Generation Polygenic Selection Shapes Fitness-Related Traits across Environments in Juvenile Sea Bream](https://www.mdpi.com/2073-4425/11/4/398/htm#app1-genes-11-00398), the author estimated the expected distribution of allele frequency changes (deltap) due to finite sample sizes in the absence of selection to generate null expectations.

### Conceptional steps:

1) a panmictic common gene pool of finite size (i.e. the real population)

2) two samples of size N1 and N2 are drawn within the same generation

3) compare the observed allele frequency difference - ŒîP=abs(P1‚àíP2) with the distribution of ŒîP expected from random sampling effects (i.e. due to finite sample size effects) and obtain the p-values.    

### Perform the SGS test for DelBay19 challenge experiment

> The posterior probability distribution of ùëç in the common gene pool given X=ùëò observed allele counts in N1 diploid individuals was used to obtain the null distribution of ŒîP between the two samples of size N1 and N2. For that, we assumed that the two samples are drawn from the same common gene pool, and used the posterior probability distribution of Z conditioned the first sample of size N1 to predict the null distribution of allele counts in the second sample of size N2. Finally, the distribution of allele frequency differences between the two samples was computed and compared to the observed value of ŒîP to estimate a P-value.

I used "the posterior probability distribution of Z conditioned the first sample of size N1 to predict the null distribution of allele counts in the second sample of size N2". This is done by using the *sample* function in the R, which allows me to randomly draw two p (i.e. allele frequency) values based on probability distribution conditioned the first N1. Then I simply calculate the differences between two p values - i.e. deltap.

```R
# SGS test
Rscript --verbose SGS_DelBay19.R

# check the result
require(data.table)
library(ggplot2)
# load the p-value results
DT <- fread("p_value_list_all.txt")
print(DT)
                  V1       V2     V3
      1: NC_035780.1     1466 0.5507
      2: NC_035780.1     1472 0.3342
      3: NC_035780.1     4241 0.1308
      4: NC_035780.1     4277 0.8981
      5: NC_035780.1     4928 0.5928
     ---                            
1885316: NC_035789.1 32597188 0.4721
1885317: NC_035789.1 32597351 0.0956
1885318: NC_035789.1 32597701 0.8153
1885319: NC_035789.1 32597840 0.0950
1885320: NC_035789.1 32597934 0.2616
DT$V3 <- as.numeric(DT$V3)
# measure the number of snp with p-value < 0.001
length(DT$V3[DT$V3 < 0.001])
[1] 35222
# plot the distribution of p-values across the whole genome
ggplot(data=DT, aes(DT$V3)) + 
  geom_histogram(bins = 200)+
  xlab("p-value")
# obtain the p-value after fdr correction
DT$V3 <- round(p.adjust((DT$V3), "fdr"), 5)
length(DT$V3[DT$V3 < 0.001])
[1] 11516
```

- p-value density plot. The left tail in the distribution sould include some false-positives.

<img src="https://hzz0024.github.io/images/SGS/p-value_distribution.jpeg" alt="img" width="800"/>

- Some questions that need to be addressed from this SGS test,

1) The number of outliers after FDR correction is so high (11516). Actually all these p-values are 0, meaning that none of the deltap (10000 values) from the null-model is larger than the observed deltap. This looks not accurate. Perhaps I should use One-Sample t-test to obtain the p-value.

I also tried to use 99.9% percentile as a threshold to filer out the potential ouliters, it ends up with 50504 SNPs (still too much) 

The One-Sample t-test behaves wired, which generate a lot of 1 and 0 p-values. This is probably due to that one-tailed t-test compares the means of non-model to the observed deltap but not the distribution. The confidence interval is close to the mean after 10000 repeated deltap calculation. 

```sh
# simple code for one-tailed t-test 
# delta_ps is the list of deltap produced from the non-model, while obs_delta is the actual deltap from challenge experiment
res = t.test(delta_ps, mu = obs_delta, alternative='less', conf.level = 0.95)
```

2) The pi need to be corrected by the actual number of variant and invariant sites covered in global and window estimates. Anna Tigano did that and posted the script here [https://github.com/atigano/Peromyscus_eremicus_genome/tree/master/variant_calling_ANGSD](https://github.com/atigano/Peromyscus_eremicus_genome/tree/master/variant_calling_ANGSD). I will follow her steps and edit the script for my data usage. This pi value is important to the SGS analyses. My current SGS analysis uses the global theta calcualted from tW(Watterson theta)/nSites, which only take the variant sites into account.

Below is the code for pi correction,

``sh
#!/bin/bash
#SBATCH --partition=shared,macmanes
#SBATCH --job-name=piwin
#SBATCH --output=piwin_%j.log
#SBATCH --mem=400GB #MB
####pi_correction_pipeline_peer_global_noout.sh
#sbatch ~/scripts/pi_correction_pipeline_peer_global_noout.sh 50
#sbatch ~/scripts/pi_correction_pipeline_peer_global_noout.sh 1

WIN=$1 ###win size in kb

module load linuxbrew/colsa
###out of the loop
###make windows
bedtools makewindows -g ~/genomes/Peer/Peer1.7.2.fasta.fai -w ${WIN}000 | awk '$3 ~ /000$/' | sed 's/ /\t/g'> genome_windows_${WIN}k.bed

###make bed file from the theta file containing pi
tail -n +2 angsd_peer_global_noout_folded.sfs.thetas.site > angsd_peer_global_noout_folded.sfs.thetas.site_nohead
cut -f2 angsd_peer_global_noout_folded.sfs.thetas.site_nohead | awk '{$1 = $1 + 1; print}' | paste angsd_peer_global_noout_folded.sfs.thetas.site_nohead - | awk 'BEGIN {FS="\t"};{ print $1"\t"$2"\t"$8"\t"$4}' | sed 's/ //g' > pi_peer_global_noout.bed

###in the loop
for CHR in `cat chromosomes.txt`; do ###list of chromosomes in chromosomes.txt file; do
###make bed file for all variant and invariant sites for each chromosome
grep "$CHR" angsd_peer_global_noout_allvar.mafs > angsd_peer_global_noout_allvar_${CHR}.mafs
cut -f 1,2 angsd_peer_global_noout_allvar_${CHR}.mafs > peer_global_noout_allvar.sites_${CHR}.txt
cut -f2 peer_global_noout_allvar.sites_${CHR}.txt | awk '{$1 = $1 + 1; print}' | paste peer_global_noout_allvar.sites_${CHR}.txt - | sed 's/ //g'> peer_global_noout_allvar.sites_${CHR}.bed

###split the genome window file in chr
grep "$CHR" genome_windows_${WIN}k.bed > genome_windows_${WIN}k_${CHR}.bed

###calculate the number of sites in each window for each chromosome
bedtools coverage -a genome_windows_${WIN}k_${CHR}.bed -b peer_global_noout_allvar.sites_${CHR}.bed -counts > allsites_${WIN}kbwin_${CHR}.txt
cut -f4 allsites_${WIN}kbwin_${CHR}.txt | sed 's/\t0/NA/g' > allsites_${WIN}kwin_NA_${CHR}.txt

###split the per site theta file
grep "$CHR" pi_peer_global_noout.bed > pi_peer_global_noout_${CHR}.bed

awk '{print exp($4)}' pi_peer_global_noout_${CHR}.bed | paste pi_peer_global_noout_${CHR}.bed - > pi_peer_global_noout_log_${CHR}.bed

bedtools map -a genome_windows_${WIN}k_${CHR}.bed -b pi_peer_global_noout_log_${CHR}.bed -c 5 -o sum | sed 's/\t[.]/\tNA/g' - > pi_peer_global_noout_log_${WIN}kbwin_${CHR}.txt
###pi_peer_global_noout_log_50kbwin_chr2_pilon.txt 

paste pi_peer_global_noout_log_${WIN}kbwin_${CHR}.txt allsites_${WIN}kwin_NA_${CHR}.txt | sed 's/[.]\t/NA\t/g' - > pi_peer_global_noout_log_${WIN}kbwin_sites_${CHR}.txt

awk '{if(/NA/)var="NA";else var=$4/$5;print var}' pi_peer_global_noout_log_${WIN}kbwin_sites_${CHR}.txt | paste pi_peer_global_noout_log_${WIN}kbwin_sites_${CHR}.txt - > pi_peer_global_noout_log_${WIN}kbwin_sites_corrected_${CHR}.txt

done
```

