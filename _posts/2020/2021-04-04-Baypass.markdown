---
comments: true
title: Baypass analysis
date: '2021-04-04 12:00'
tags:
  - DelBay
  - Wild 
  - WGS
  - Baypass
categories:
  - WGS data analysis
--- 

### What is Baypass?

Baypass is a program designed to associate the adaptive differentiation to environmental variables [Baypass](http://www1.montpellier.inra.fr/CBGP/software/baypass/).   

The publication is [here](https://www.genetics.org/content/201/4/1555) And there is a good manual [here](http://www1.montpellier.inra.fr/CBGP/software/baypass/files/BayPass_manual_2.2.pdf)

### Baypass input

The pipeline for Baypass run was initially developed by [Claire MÃ©rot](https://github.com/clairemerot/selection_analysis), with some modifications. 

In terms of the Baypass input, it requires a allele count file, a popoulation information file, and an environment data file.

First is the allele count files, which is produced by Angsd and formated by Yann Dorant's [toolbox](https://gitlab.com/YDorant/Toolbox).

Here I have prepared five .mafs for the whole wild transect populations.

```sh
#############################################################################
pwd # main folder
/workdir/hz269/DelBay_all_angsd/13_env_gen_association/selection_analysis-master

cd /workdir/hz269/DelBay_all_angsd/13_env_gen_association/selection_analysis-master/02_raw_data # folder for raw maf files
ls *.mafs

ARN_maf0.05_pctind0.7_maxdepth3.mafs  
COH_maf0.05_pctind0.7_maxdepth3.mafs  
NB_maf0.05_pctind0.7_maxdepth3.mafs
HC_maf0.05_pctind0.7_maxdepth3.mafs
SR_maf0.05_pctind0.7_maxdepth3.mafs
										
###ANALYSING_MAF_SELECTION_TESTS_ETC

#############################################################################
cat cat 02_extract_format_maf.sh

###02_extract_format_maf
#or to extract maf & proceed straight to formatting maf for various analyses
#to extract maf and gather all pop maf in one file (same as above)+ format them for rda & various analysis
#it will aslo output in the list of snps for which maf was calculated in all populations (represented by the min % of IND given as filter
source 01_scripts/01_config.sh
Rscript 01_scripts/Rscripts/extract_format_maf.r "$MIN_MAF" "$PERCENT_IND" "$POP1_FILE" "$ANGSD_PATH" "$MAX_DEPTH_FACTOR"

#############################################################################
cat extract_format_maf.r

#this R script extract maf in a single file for all populations
library(dplyr)


argv <- commandArgs(T)
MIN_MAF <- argv[1]
PERCENT_IND <- argv[2]
POP<-argv[3]
ANGSD_PATH<- argv[4]
MAX_DEPTH_FACTOR<-argv[5]

#read sites files
sites<-read.table(paste0(ANGSD_PATH,"/02_raw_data/sites_all_maf",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR), header=F)
colnames(sites)<-c("chromo", "position", "major", "minor")

#read pop file
print(POP)
pop<-read.table(POP, header=F)
npop<-dim(pop)[1]
pop_group<-"pop" #unlist(strsplit(unlist(strsplit(POP,"/"))[2],".txt"))


#join by chromoome and position the sites and the frequencies in each population
print("join by chromoome and position the sites and the frequencies in each population")
MAFall<-sites
for (i in 1:npop)
  {
    pi<-pop[i,1]
    MAFi<-read.delim(paste0(ANGSD_PATH,"/02_raw_data/",pi,"_maf",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".mafs"), header=T)
    MAFi<-MAFi[,c(1,2,6,7)]
    colnames(MAFi)<-c("chromo", "position", paste("freq", pi, sep=""),paste("n", pi, sep=""))
    head(MAFi)
    MAFall<-left_join(MAFall, MAFi, by=c("chromo", "position"))
}
head(MAFall)
nSNP<-dim(MAFall)[1]
print(paste("total nb of snp for which we ran the analysis = ", dim(MAFall)[1]))
print(paste("total nb of pop for which we ran the analysis = ", (dim(MAFall)[2]-4)/2))

which (MAFall=="NA")
#select the position which are not NA
MAFall<-MAFall[which((rowSums(MAFall[,5:dim(MAFall)[2]])>=0)),]

nSNP_no_na<-dim(MAFall)[1]
print(paste("total nb of snp kept because they were covered in all populations by the chosen % of ind = ", dim(MAFall)[1]))

write.table(MAFall, paste0("02_raw_data/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".mafs"), quote=F, sep=" ")
#write the list of SNP infered in all populations
write.table(MAFall[,1:4], paste0("02_raw_data/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".snps"), quote=F, sep=" ")



#format for RDA & lfmm & FLK
#row are snp
#col are pop
print("format for rda/lfmm/flk")
freq_col<-seq(5,(3+npop*2), by=2)
maf_matrix<-(MAFall[,freq_col])
colnames(maf_matrix)<-pop[,1]
rownames(maf_matrix)<-paste(MAFall$chromo, MAFall$position, sep="_")
head(maf_matrix)

#for lfmm
write.table(t(maf_matrix), paste0("04_lfmm/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".lfmm"), quote=F, row.names = F, col.names = F)

#for FLK add colnames
write.table(maf_matrix, paste0("05_flk/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".mafs.flkT"), quote=F, row.names = F)
#we would need also a matrix of reynolds distances? see ld-pruned methods, removing outliers,e tc

#for rda add rownames
write.table(maf_matrix, paste0("03_rda/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".mafs.rda"), quote=F)


#for Baypass
#row are snp
#col are pop (2 col per pop separated by a space, with nAllele M, nAllele m)
print("format for baypass")
BayPass_matrix<-matrix(ncol=(npop*2), nrow=nSNP_no_na)
for (i in 1:npop)
	{
	BayPass_matrix[,(2*i-1)]<- round(MAFall[,4+(2*i-1)]*2*MAFall[,5+(2*i-1)],0)
	BayPass_matrix[,(2*i)]<- round((1-MAFall[,4+(2*i-1)])*2*MAFall[,5+(2*i-1)],0)
	}
head(BayPass_matrix)
write.table(BayPass_matrix, paste0("06_baypass/by_",pop_group,"_",MIN_MAF,"_pctind",PERCENT_IND,"_maxdepth",MAX_DEPTH_FACTOR,".mafs.baypass"), quote=F, row.names = F, col.names = F)

##I have somewhere a script to prepare the maf matrix for bayescan but bayescan is just too long to run on so many snps.
```

### run baypass basic

```sh
cat 06_baypass.sh

#!/bin/bash

# no control
/workdir/hz269/DelBay_all_angsd/13_env_gen_association/baypass_2.2/sources/g_baypass -npop 5 -gfile 06_baypass/by_pop_0.05_pctind0.7_maxdepth3.mafs.baypass -outprefix 06_baypass/by_pop_0.05_pctind0.7_maxdepth3.mafs.baypass.output -nthreads 8
```

### Baypass with control on population structure

Best practices suggest to first run baypass on the LD-pruned SNP list and to extract the covariance matrix between population (mat_omega), and then use it as a covariate in the baypass model.

To obtain the LD-pruned SNP list, we need to use ngsLD tool [https://github.com/fgvieira/ngsLD](https://github.com/fgvieira/ngsLD).

#### Baypass with LD-pruned SNP list

The workflow is listed below:

1. Run Angsd on all wild populaitons and obtain the beagle file (with -doGlf 2 option).  

Wild population:

```sh
cat 02_depth_WILD.sh

$angsd -P $NB_CPU \
-doMaf 1 -GL 1 -doGlf 2 -doDepth 1 -doMajorMinor 1 -doCounts 1 $REGIONS \
-anc $ANC -ref $ANC -remove_bads 1 -skipTriallelic 1 -doQsDist 1 -minMapQ 30 -minQ 20 -SNP_pval 1e-6 -rmTriallelic 1e-6  \
-minInd $MIN_IND -minMaf $MIN_MAF -maxDepth 5000 -setMinDepth $MIN_DEP \
-b $WILD_all -out "/local/workdir/hz269/DelBay_all_angsd/02_depth/"$target"_maf"$MIN_MAF"_minmapq30_minq20_pctind"$PERCENT_IND"_CV30_masked"

Number of samples: 234          
SNP depth: mean is 527, SD is 156, maxdepth 994 

cat 03_global_WILD.sh

$angsd -P $NB_CPU \
 -doMaf 1 -dosaf 1 -GL 1 -doGlf 2 -doMajorMinor 1 -doCounts 1 \
 -doDepth 1 -doIBS 2 -makeMatrix 1 -doCov 1 $REGIONS \
 -doPlink 2 -doGeno 4 -doPost 1 -postCutoff 0.8 \
 -maxDepth 2000 -dumpCounts 2 -anc $ANC -remove_bads 1 -rmTriallelic 1e-6 \
 -minMapQ 30 -minQ 20 -minInd $MIN_IND -minMaf $MIN_MAF \
 -setMinDepth 78 -setMaxDepth 994 -SNP_pval 1e-6 -b $WILD_all \
 -out "/local/workdir/hz269/DelBay_all_angsd/03_global/"$target"_maf"$MIN_MAF"_minq20_minmq30_pctind"$PERCENT_IND"_CV30_masked_noinvers"

zcat WILD_all_maf0.05_minq20_minmq30_pctind0.7_CV30_masked_noinvers.mafs.gz | wc -l
1680986 

cat wt_script_15_ngsLD_WILD.sh
#!/bin/bash
# Read a string with spaces using for loop
for i in {1..10}
do
    echo -e '#!/bin/bash\ntarget="WILD_all"\nNB_CPU=20 #change accordingly\nREGIONS="-rf chr_list_chr'$i'.txt" \nsource /local/workdir/hz269/DelBay_all_angsd/01_scripts/01_config.sh\nN_IND=$(wc -l $WILD_all | cut -d " " -f 1)\nMIN_IND=$(($N_IND*7/10))\n\necho "Ouput can be used for depth evaluation with all individuals listed in $WILD_all"\necho "keep loci with at leat one read for n individuals = $MIN_IND, which is 70% of total $N_IND individuals"\necho "filter on allele frequency = $MIN_MAF"\n\n$angsd -P $NB_CPU \\\n -doMaf 1 -dosaf 1 -GL 1 -doGlf 2 -doMajorMinor 1 -doCounts 1 \\\n -doDepth 1 -doIBS 2 -makeMatrix 1 -doCov 1 $REGIONS \\\n -doPlink 2 -doGeno 4 -doPost 1 -postCutoff 0.8 \\\n -maxDepth 2000 -dumpCounts 2 -anc $ANC -remove_bads 1 -rmTriallelic 1e-6 \\\n -minMapQ 30 -minQ 20 -minInd $MIN_IND -minMaf $MIN_MAF \\\n -setMinDepth 78 -setMaxDepth 994 -SNP_pval 1e-6 -b $WILD_all \\\n -out "/local/workdir/hz269/DelBay_all_angsd/15_LD_prunning/"$target"_maf"$MIN_MAF"_minq20_minmq30_pctind"$PERCENT_IND"_CV30_masked_noinvers_chr'$i'"' >> formal/'15_ngsLD_WILD_chr'$i'.sh'
done
```

2. Run ngsLD on beagle file / Run Plink on called genotype and do the pruning 


```sh
cat 15_1_ngsLD_WILD.sh
for i in {1..10}; do
    zcat 'WILD_all_maf0.05_minq20_minmq30_pctind0.7_CV30_masked_noinvers_chr'$i'.mafs.gz' | cut -f 1,2 | tail -n +2 > 'WILD_chr'$i'.pos.txt'
    cat 'WILD_chr'$i'.pos.txt' | wc -l
done

cat 15_2_ngsLD_WILD.sh
#!/bin/sh

for i in {1..10}; do
 NUM_SITES=$(cat 'WILD_chr'$i'.pos.txt' | wc -l)
 /programs/ngsLD/ngsLD \
    --geno 'WILD_all_maf0.05_minq20_minmq30_pctind0.7_CV30_masked_noinvers_chr'$i'.beagle.gz' \
    --pos 'WILD_chr'$i'.pos.txt' \
    --n_ind 234 \
    --n_sites $NUM_SITES \
    --out 'WILD_chr'$i'.ngsld.output' \
    --probs \
    --max_kb_dist 10 \ #--rnd_sample 0.1 \
    --seed 1000 \
    --min_maf 0.05 \
    --n_threads 8
done

cat wt_15_3_ngsLD_WILD_by_chr.sh
#!/bin/sh

export PERL5LIB=/programs/PERL/lib/perl5
export PATH=/programs/ngsLD-1.1.1:/programs/ngsLD-1.1.1/scripts:$PATH

for i in {1..10}; do
echo -e '#!/bin/sh\nexport PERL5LIB=/programs/PERL/lib/perl5\nexport PATH=/programs/ngsLD-1.1.1:/programs/ngsLD-1.1.1/scripts:$PATH\n\nprune_graph.pl \\\n --in_file WILD_chr'$i'.ngsld.output \\\n --max_kb_dist 10 --min_weight 0.2 \\\n --out WILD_chr'$i'.unlinked.id' >> "15_3_LD_prunning_WILD_"$i".sh"
echo -e 'sbatch --job-name=WILD_chr'$i' --output=/workdir/hz269/DelBay_all_angsd/15_LD_prunning/log/15_3_LD_prunning_WILD_'$i'.log --nodes=1 --ntasks=10 --mem=80000 15_3_LD_prunning_WILD_'$i'.sh' >> run_15_3_LD_prunning.sh
done
```

3. Run BayPass again on pruned SNP list (need to generate the .mafs file on each subpopulation)

```sh
cp WILD_all_1680985.snplist.txt sites_all_maf0.05_pctind0.7_maxdepth3
[hz269@cbsuhare 02_raw_data]$ cp WILD_pruned_723274.snplist.txt sites_all_pruned_maf0.05_pctind0.7
[hz269@cbsuhare 02_raw_data]$ cat sites_all_maf0.05_pctind0.7_maxdepth3 | wc -l
1680985
[hz269@cbsuhare 02_raw_data]$ cat sites_all_pruned_maf0.05_pctind0.7 | wc -;
 723274 2893096 17969611 -
[hz269@cbsuhare 02_raw_data]$ cat sites_all_pruned_maf0.05_pctind0.7 | wc -l
723274    
```





